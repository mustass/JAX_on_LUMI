Get loader
Files already downloaded and verified
x shape is (40000, 32, 32, 3)
Traceback (most recent call last):
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 249, in <module>
    run(1)
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 244, in run
    ggn_vp(loader,state,mesh_sharding,sharding, global_shape_x)
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 120, in ggn_vp
    ggn_vp += jax.lax.scan(body_fn, init_carry, x)[0]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 115, in body_fn
    _, J = jax.jvp(model_on_data, (params_vec,), (vec,))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 114, in <lambda>
    model_on_data = lambda p: apply_fn_vec(p, x_)
                              ^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 92, in apply_fn_vec
    return state.apply_fn({'params': unflatten_fn(params_vec)}, x)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 42, in __call__
    x = nn.relu(nn.Dense(128,kernel_init=self.dense_init,
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/venv/lib/python3.12/site-packages/flax/linen/linear.py", line 256, in __call__
Get loader
Files already downloaded and verified
x shape is (40000, 32, 32, 3)
Traceback (most recent call last):
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 249, in <module>
    run(1)
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 244, in run
    ggn_vp(loader,state,mesh_sharding,sharding, global_shape_x)
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 120, in ggn_vp
    ggn_vp += jax.lax.scan(body_fn, init_carry, x)[0]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 115, in body_fn
    _, J = jax.jvp(model_on_data, (params_vec,), (vec,))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 114, in <lambda>
    model_on_data = lambda p: apply_fn_vec(p, x_)
                              ^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 92, in apply_fn_vec
    return state.apply_fn({'params': unflatten_fn(params_vec)}, x)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 42, in __call__
    x = nn.relu(nn.Dense(128,kernel_init=self.dense_init,
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/venv/lib/python3.12/site-packages/flax/linen/linear.py", line 256, in __call__
    kernel = self.param(
             ^^^^^^^^^^^
flax.errors.ScopeParamShapeError: Initializer expected to generate shape (57600, 128) but got shape (1920, 128) instead for parameter "kernel" in "/Dense_0". (https://flax.readthedocs.io/en/latest/api_reference/flax.errors.html#flax.errors.ScopeParamShapeError)
--------------------
For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.
    kernel = self.param(
             ^^^^^^^^^^^
flax.errors.ScopeParamShapeError: Initializer expected to generate shape (57600, 128) but got shape (1920, 128) instead for parameter "kernel" in "/Dense_0". (https://flax.readthedocs.io/en/latest/api_reference/flax.errors.html#flax.errors.ScopeParamShapeError)
--------------------
For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.
Get loader
Files already downloaded and verified
x shape is (40000, 32, 32, 3)
Traceback (most recent call last):
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 249, in <module>
    run(1)
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 244, in run
    ggn_vp(loader,state,mesh_sharding,sharding, global_shape_x)
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 120, in ggn_vp
    ggn_vp += jax.lax.scan(body_fn, init_carry, x)[0]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 115, in body_fn
    _, J = jax.jvp(model_on_data, (params_vec,), (vec,))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 114, in <lambda>
    model_on_data = lambda p: apply_fn_vec(p, x_)
                              ^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 92, in apply_fn_vec
    return state.apply_fn({'params': unflatten_fn(params_vec)}, x)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 42, in __call__
    x = nn.relu(nn.Dense(128,kernel_init=self.dense_init,
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/venv/lib/python3.12/site-packages/flax/linen/linear.py", line 256, in __call__
    kernel = self.param(
             ^^^^^^^^^^^
flax.errors.ScopeParamShapeError: Initializer expected to generate shape (57600, 128) but got shape (1920, 128) instead for parameter "kernel" in "/Dense_0". (https://flax.readthedocs.io/en/latest/api_reference/flax.errors.html#flax.errors.ScopeParamShapeError)
--------------------
For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.
Get loader
Files already downloaded and verified
x shape is (40000, 32, 32, 3)
Traceback (most recent call last):
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 249, in <module>
Get loader
Files already downloaded and verified
x shape is (40000, 32, 32, 3)
Traceback (most recent call last):
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 249, in <module>
    run(1)
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 244, in run
    run(1)
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 244, in run
    ggn_vp(loader,state,mesh_sharding,sharding, global_shape_x)
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 120, in ggn_vp
    ggn_vp += jax.lax.scan(body_fn, init_carry, x)[0]
    ggn_vp(loader,state,mesh_sharding,sharding, global_shape_x)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 115, in body_fn
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 120, in ggn_vp
    _, J = jax.jvp(model_on_data, (params_vec,), (vec,))
    ggn_vp += jax.lax.scan(body_fn, init_carry, x)[0]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 114, in <lambda>
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 115, in body_fn
    model_on_data = lambda p: apply_fn_vec(p, x_)
                              ^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 92, in apply_fn_vec
    _, J = jax.jvp(model_on_data, (params_vec,), (vec,))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 114, in <lambda>
    return state.apply_fn({'params': unflatten_fn(params_vec)}, x)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 42, in __call__
    model_on_data = lambda p: apply_fn_vec(p, x_)
                              ^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 92, in apply_fn_vec
    x = nn.relu(nn.Dense(128,kernel_init=self.dense_init,
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/venv/lib/python3.12/site-packages/flax/linen/linear.py", line 256, in __call__
    return state.apply_fn({'params': unflatten_fn(params_vec)}, x)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 42, in __call__
    kernel = self.param(
             ^^^^^^^^^^^
flax.errors.ScopeParamShapeError: Initializer expected to generate shape (57600, 128) but got shape (1920, 128) instead for parameter "kernel" in "/Dense_0". (https://flax.readthedocs.io/en/latest/api_reference/flax.errors.html#flax.errors.ScopeParamShapeError)
--------------------
For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.
    x = nn.relu(nn.Dense(128,kernel_init=self.dense_init,
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/venv/lib/python3.12/site-packages/flax/linen/linear.py", line 256, in __call__
    kernel = self.param(
             ^^^^^^^^^^^
flax.errors.ScopeParamShapeError: Initializer expected to generate shape (57600, 128) but got shape (1920, 128) instead for parameter "kernel" in "/Dense_0". (https://flax.readthedocs.io/en/latest/api_reference/flax.errors.html#flax.errors.ScopeParamShapeError)
--------------------
For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.
Get loader
Files already downloaded and verified
x shape is (40000, 32, 32, 3)
Traceback (most recent call last):
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 249, in <module>
    run(1)
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 244, in run
    ggn_vp(loader,state,mesh_sharding,sharding, global_shape_x)
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 120, in ggn_vp
    ggn_vp += jax.lax.scan(body_fn, init_carry, x)[0]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 115, in body_fn
    _, J = jax.jvp(model_on_data, (params_vec,), (vec,))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 114, in <lambda>
Get loader
Files already downloaded and verified
x shape is (40000, 32, 32, 3)
Traceback (most recent call last):
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 249, in <module>
    model_on_data = lambda p: apply_fn_vec(p, x_)
    run(1)
Get loader
Files already downloaded and verified
x shape is (40000, 32, 32, 3)
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 244, in run
                              ^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 92, in apply_fn_vec
Traceback (most recent call last):
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 249, in <module>
Get loader
Files already downloaded and verified
x shape is (40000, 32, 32, 3)
    return state.apply_fn({'params': unflatten_fn(params_vec)}, x)
    ggn_vp(loader,state,mesh_sharding,sharding, global_shape_x)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 42, in __call__
Traceback (most recent call last):
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 249, in <module>
    x = nn.relu(nn.Dense(128,kernel_init=self.dense_init,
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/venv/lib/python3.12/site-packages/flax/linen/linear.py", line 256, in __call__
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 120, in ggn_vp
Get loader
Files already downloaded and verified
x shape is (40000, 32, 32, 3)
    run(1)
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 244, in run
    kernel = self.param(
             ^^^^^^^^^^^
flax.errors.ScopeParamShapeError: Initializer expected to generate shape (57600, 128) but got shape (1920, 128) instead for parameter "kernel" in "/Dense_0". (https://flax.readthedocs.io/en/latest/api_reference/flax.errors.html#flax.errors.ScopeParamShapeError)
--------------------
For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.
    ggn_vp += jax.lax.scan(body_fn, init_carry, x)[0]
Traceback (most recent call last):
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 249, in <module>
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 115, in body_fn
    run(1)
    ggn_vp(loader,state,mesh_sharding,sharding, global_shape_x)
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 244, in run
    _, J = jax.jvp(model_on_data, (params_vec,), (vec,))
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 120, in ggn_vp
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 114, in <lambda>
    ggn_vp += jax.lax.scan(body_fn, init_carry, x)[0]
    run(1)
    model_on_data = lambda p: apply_fn_vec(p, x_)
    ggn_vp(loader,state,mesh_sharding,sharding, global_shape_x)
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 244, in run
                              ^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 92, in apply_fn_vec
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 115, in body_fn
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 120, in ggn_vp
    _, J = jax.jvp(model_on_data, (params_vec,), (vec,))
    return state.apply_fn({'params': unflatten_fn(params_vec)}, x)
    ggn_vp += jax.lax.scan(body_fn, init_carry, x)[0]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 42, in __call__
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 114, in <lambda>
Get loader
Files already downloaded and verified
x shape is (40000, 32, 32, 3)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 115, in body_fn
    ggn_vp(loader,state,mesh_sharding,sharding, global_shape_x)
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 120, in ggn_vp
Get loader
Files already downloaded and verified
x shape is (40000, 32, 32, 3)
Traceback (most recent call last):
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 249, in <module>
    run(1)
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 244, in run
    ggn_vp(loader,state,mesh_sharding,sharding, global_shape_x)
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 120, in ggn_vp
    ggn_vp += jax.lax.scan(body_fn, init_carry, x)[0]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 115, in body_fn
    _, J = jax.jvp(model_on_data, (params_vec,), (vec,))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 114, in <lambda>
    model_on_data = lambda p: apply_fn_vec(p, x_)
                              ^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 92, in apply_fn_vec
    return state.apply_fn({'params': unflatten_fn(params_vec)}, x)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 42, in __call__
    x = nn.relu(nn.Dense(128,kernel_init=self.dense_init,
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/venv/lib/python3.12/site-packages/flax/linen/linear.py", line 256, in __call__
    kernel = self.param(
             ^^^^^^^^^^^
flax.errors.ScopeParamShapeError: Initializer expected to generate shape (57600, 128) but got shape (1920, 128) instead for parameter "kernel" in "/Dense_0". (https://flax.readthedocs.io/en/latest/api_reference/flax.errors.html#flax.errors.ScopeParamShapeError)
--------------------
For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.
Get loader
Files already downloaded and verified
x shape is (40000, 32, 32, 3)
Traceback (most recent call last):
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 249, in <module>
    run(1)
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 244, in run
    ggn_vp(loader,state,mesh_sharding,sharding, global_shape_x)
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 120, in ggn_vp
    ggn_vp += jax.lax.scan(body_fn, init_carry, x)[0]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 115, in body_fn
    _, J = jax.jvp(model_on_data, (params_vec,), (vec,))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 114, in <lambda>
    model_on_data = lambda p: apply_fn_vec(p, x_)
                              ^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 92, in apply_fn_vec
    return state.apply_fn({'params': unflatten_fn(params_vec)}, x)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 42, in __call__
    x = nn.relu(nn.Dense(128,kernel_init=self.dense_init,
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/venv/lib/python3.12/site-packages/flax/linen/linear.py", line 256, in __call__
    kernel = self.param(
             ^^^^^^^^^^^
flax.errors.ScopeParamShapeError: Initializer expected to generate shape (57600, 128) but got shape (1920, 128) instead for parameter "kernel" in "/Dense_0". (https://flax.readthedocs.io/en/latest/api_reference/flax.errors.html#flax.errors.ScopeParamShapeError)
--------------------
For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.
Traceback (most recent call last):
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 249, in <module>
    x = nn.relu(nn.Dense(128,kernel_init=self.dense_init,
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    model_on_data = lambda p: apply_fn_vec(p, x_)
    _, J = jax.jvp(model_on_data, (params_vec,), (vec,))
  File "/project/project_465001020/hackathon/venv/lib/python3.12/site-packages/flax/linen/linear.py", line 256, in __call__
                              ^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 92, in apply_fn_vec
    ggn_vp += jax.lax.scan(body_fn, init_carry, x)[0]
Get loader
Files already downloaded and verified
x shape is (40000, 32, 32, 3)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 114, in <lambda>
Traceback (most recent call last):
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 249, in <module>
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 115, in body_fn
    return state.apply_fn({'params': unflatten_fn(params_vec)}, x)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 42, in __call__
    model_on_data = lambda p: apply_fn_vec(p, x_)
                              ^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 92, in apply_fn_vec
    _, J = jax.jvp(model_on_data, (params_vec,), (vec,))
    run(1)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 114, in <lambda>
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 244, in run
Get loader
Files already downloaded and verified
x shape is (40000, 32, 32, 3)
Traceback (most recent call last):
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 249, in <module>
    x = nn.relu(nn.Dense(128,kernel_init=self.dense_init,
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/venv/lib/python3.12/site-packages/flax/linen/linear.py", line 256, in __call__
    run(1)
    return state.apply_fn({'params': unflatten_fn(params_vec)}, x)
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 244, in run
    model_on_data = lambda p: apply_fn_vec(p, x_)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 42, in __call__
                              ^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 92, in apply_fn_vec
    ggn_vp(loader,state,mesh_sharding,sharding, global_shape_x)
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 120, in ggn_vp
    x = nn.relu(nn.Dense(128,kernel_init=self.dense_init,
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/venv/lib/python3.12/site-packages/flax/linen/linear.py", line 256, in __call__
    return state.apply_fn({'params': unflatten_fn(params_vec)}, x)
    ggn_vp(loader,state,mesh_sharding,sharding, global_shape_x)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 42, in __call__
    run(1)
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 120, in ggn_vp
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 244, in run
    ggn_vp += jax.lax.scan(body_fn, init_carry, x)[0]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 115, in body_fn
    x = nn.relu(nn.Dense(128,kernel_init=self.dense_init,
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/venv/lib/python3.12/site-packages/flax/linen/linear.py", line 256, in __call__
    ggn_vp += jax.lax.scan(body_fn, init_carry, x)[0]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 115, in body_fn
    _, J = jax.jvp(model_on_data, (params_vec,), (vec,))
    ggn_vp(loader,state,mesh_sharding,sharding, global_shape_x)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 114, in <lambda>
Get loader
Files already downloaded and verified
x shape is (40000, 32, 32, 3)
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 120, in ggn_vp
Traceback (most recent call last):
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 249, in <module>
    _, J = jax.jvp(model_on_data, (params_vec,), (vec,))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 114, in <lambda>
    model_on_data = lambda p: apply_fn_vec(p, x_)
                              ^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 92, in apply_fn_vec
    ggn_vp += jax.lax.scan(body_fn, init_carry, x)[0]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 115, in body_fn
    model_on_data = lambda p: apply_fn_vec(p, x_)
                              ^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 92, in apply_fn_vec
    return state.apply_fn({'params': unflatten_fn(params_vec)}, x)
    run(1)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 42, in __call__
    _, J = jax.jvp(model_on_data, (params_vec,), (vec,))
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 244, in run
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 114, in <lambda>
    return state.apply_fn({'params': unflatten_fn(params_vec)}, x)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 42, in __call__
    x = nn.relu(nn.Dense(128,kernel_init=self.dense_init,
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/venv/lib/python3.12/site-packages/flax/linen/linear.py", line 256, in __call__
    model_on_data = lambda p: apply_fn_vec(p, x_)
    ggn_vp(loader,state,mesh_sharding,sharding, global_shape_x)
                              ^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 92, in apply_fn_vec
    x = nn.relu(nn.Dense(128,kernel_init=self.dense_init,
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/venv/lib/python3.12/site-packages/flax/linen/linear.py", line 256, in __call__
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 120, in ggn_vp
    return state.apply_fn({'params': unflatten_fn(params_vec)}, x)
    ggn_vp += jax.lax.scan(body_fn, init_carry, x)[0]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 42, in __call__
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 115, in body_fn
    x = nn.relu(nn.Dense(128,kernel_init=self.dense_init,
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/venv/lib/python3.12/site-packages/flax/linen/linear.py", line 256, in __call__
    _, J = jax.jvp(model_on_data, (params_vec,), (vec,))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 114, in <lambda>
    model_on_data = lambda p: apply_fn_vec(p, x_)
    kernel = self.param(
             ^^^^^^^^^^^
    kernel = self.param(
             ^^^^^^^^^^^
flax.errors.ScopeParamShapeError: Initializer expected to generate shape (57600, 128) but got shape (1920, 128) instead for parameter "kernel" in "/Dense_0". (https://flax.readthedocs.io/en/latest/api_reference/flax.errors.html#flax.errors.ScopeParamShapeError)
--------------------
    kernel = self.param(
             ^^^^^^^^^^^
flax.errors.ScopeParamShapeError: Initializer expected to generate shape (57600, 128) but got shape (1920, 128) instead for parameter "kernel" in "/Dense_0". (https://flax.readthedocs.io/en/latest/api_reference/flax.errors.html#flax.errors.ScopeParamShapeError)
--------------------
For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.
    kernel = self.param(
             ^^^^^^^^^^^
flax.errors.ScopeParamShapeError: Initializer expected to generate shape (57600, 128) but got shape (1920, 128) instead for parameter "kernel" in "/Dense_0". (https://flax.readthedocs.io/en/latest/api_reference/flax.errors.html#flax.errors.ScopeParamShapeError)
--------------------
For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.
    kernel = self.param(
             ^^^^^^^^^^^
flax.errors.ScopeParamShapeError: Initializer expected to generate shape (57600, 128) but got shape (1920, 128) instead for parameter "kernel" in "/Dense_0". (https://flax.readthedocs.io/en/latest/api_reference/flax.errors.html#flax.errors.ScopeParamShapeError)
--------------------
For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.
                              ^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 92, in apply_fn_vec
    kernel = self.param(
             ^^^^^^^^^^^
flax.errors.ScopeParamShapeError: Initializer expected to generate shape (57600, 128) but got shape (1920, 128) instead for parameter "kernel" in "/Dense_0". (https://flax.readthedocs.io/en/latest/api_reference/flax.errors.html#flax.errors.ScopeParamShapeError)
--------------------
For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.
flax.errors.ScopeParamShapeError: Initializer expected to generate shape (57600, 128) but got shape (1920, 128) instead for parameter "kernel" in "/Dense_0". (https://flax.readthedocs.io/en/latest/api_reference/flax.errors.html#flax.errors.ScopeParamShapeError)
--------------------
For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.
For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.
    return state.apply_fn({'params': unflatten_fn(params_vec)}, x)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/lumi_hackathon/scripts/dataparallelism_multinode_ggn.py", line 42, in __call__
    kernel = self.param(
             ^^^^^^^^^^^
flax.errors.ScopeParamShapeError: Initializer expected to generate shape (57600, 128) but got shape (1920, 128) instead for parameter "kernel" in "/Dense_0". (https://flax.readthedocs.io/en/latest/api_reference/flax.errors.html#flax.errors.ScopeParamShapeError)
--------------------
For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.
    x = nn.relu(nn.Dense(128,kernel_init=self.dense_init,
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/project/project_465001020/hackathon/venv/lib/python3.12/site-packages/flax/linen/linear.py", line 256, in __call__
    kernel = self.param(
             ^^^^^^^^^^^
flax.errors.ScopeParamShapeError: Initializer expected to generate shape (57600, 128) but got shape (1920, 128) instead for parameter "kernel" in "/Dense_0". (https://flax.readthedocs.io/en/latest/api_reference/flax.errors.html#flax.errors.ScopeParamShapeError)
--------------------
For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.
srun: error: nid007322: tasks 0-7: Exited with exit code 1
srun: Terminating StepId=8181175.0
srun: error: nid007323: tasks 8-15: Exited with exit code 1
